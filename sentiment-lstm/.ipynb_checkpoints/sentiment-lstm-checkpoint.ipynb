{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('reviews.txt', 'r') as f:\n",
    "    reviews =  f.read()\n",
    "    \n",
    "with open('labels.txt', 'r') as f:\n",
    "    labels =  f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[: 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "print (punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bromwell high is a cartoon comedy  it ran at the same time as some other programs about school life  such as  teachers   my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers   the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students  when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled          at           high  a classic line inspector i  m here to sack one of your teachers  student welcome to bromwell high  i expect that many adults of my age think that bromwell high is far fetched  what a pity that it isn  t   \n",
      "story of a man who has unnatural feelings for a pig  starts out with a opening scene that is a terrific example of absurd comedy  a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers  unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting  even those from the era should be turned off  the cryptic dialogue would make shakespeare seem easy to a third grader  on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond  future stars sally kirkland and frederic forrest can be seen briefly   \n",
      "homelessness  or houselessness as george carlin stated  has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school  work  or vote for the matter  most people think of the homeless as just a lost cause while worrying about things such as racism  the war on iraq  pressuring kids to succeed  technology  the elections  inflation  or worrying if they  ll be next to end up on the streets   br    br   but what if you were given a bet to live on the st\n"
     ]
    }
   ],
   "source": [
    "all_text = ''.join([c for c in reviews if c not in punctuation ])\n",
    "print(all_text[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = all_text.split()\n",
    "reviews = all_text.split('\\n')\n",
    "reviews = [r for r in reviews if len(r) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_set = sorted(list(set(words)))\n",
    "int2word = {i : w for i ,w in enumerate(words_set)}\n",
    "word2int = {w : i for i ,w in enumerate(words_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "targets = [0 if l == 'negative' else 1 for l in labels.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(targets[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8209, 29950, 33664, 0, 9818, 12476, 33767, 52590, 3688, 65542, 56450, 66136, 3396, 60806, 46548, 51106, 180, 57198, 37774, 63327, 3396, 64946, 43773, 73399, 32080, 65542, 64948, 51047, 37168, 40891, 66339, 5655, 65522, 8209, 29950, 56130, 56748, 33664, 43369, 11908, 66339, 52994, 65499, 33664, 64946, 65542, 57390, 66339, 63896, 23638, 65542, 32898, 62981, 72143, 9323, 57753, 55003, 65909, 65570, 47834, 64946, 49908, 65542, 48677, 45808, 65542, 72152, 59675, 1574, 53959, 40891, 45808, 65542, 57219, 31423, 35956, 2175, 65570, 62981, 71991, 31423, 56860, 65542, 21219, 32080, 72011, 0, 62980, 54119, 67367, 66339, 8738, 18861, 65542, 57198, 31423, 31805, 53133, 3688, 29950, 0, 11649, 37967, 32939, 31423, 39080, 29716, 66339, 56189, 46064, 45808, 73597, 64946, 62980, 71775, 66339, 8209, 29950, 31423, 22134, 65522, 39920, 827, 45808, 43773, 1064, 65735, 65522, 8209, 29950, 33664, 22790, 23341, 71942, 0, 49302, 65522, 33767, 33725, 64393], [62631, 45808, 0, 39681, 72143, 29036, 69125, 23139, 24475, 0, 49064, 62116, 46591, 72585, 0, 46171, 57042, 65522, 33664, 0, 65355, 21887, 45808, 247, 12476, 0, 24614, 46316, 3891, 33664, 67832, 33334, 2084, 32857, 70692, 42443, 8936, 65542, 14404, 10550, 45808, 33767, 56130, 59556, 68838, 33767, 62183, 247, 65542, 72152, 66136, 72585, 44928, 26123, 44054, 21738, 39532, 33767, 34884, 66540, 45811, 51902, 21723, 65826, 25210, 65542, 21291, 59020, 5271, 67832, 45811, 65542, 14849, 17202, 72965, 39511, 58396, 57772, 19786, 66339, 0, 65754, 27379, 46048, 0, 65000, 37600, 33767, 56130, 6035, 65499, 73568, 41752, 65735, 72585, 60806, 27108, 11455, 8936, 25492, 27591, 70641, 74028, 25492, 62099, 56393, 35793, 2175, 24984, 24657, 9323, 5271, 57782, 8030]]\n"
     ]
    }
   ],
   "source": [
    "reviews_int = []\n",
    "for r in reviews:\n",
    "    reviews_int.append([word2int[w] for w in r.split()])\n",
    "\n",
    "print(reviews_int[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "review_lens = Counter([len(l) for l in reviews_int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_lens [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2514"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(review_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews_int))\n",
    "print(len(targets))\n",
    "N = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews_int = [([0] * (N - len(r)) + r)[:200] for r in reviews_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.array(reviews_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0 33767 71424     0 58146  3809 66339 59045 65542\n",
      " 17042 58303 45808 67981 57209  2175 17290 45176 67634 66339 22218 33809\n",
      " 22518 21723  8936 66368 56130 62001 65542 23547 33664 33158  2175 51417\n",
      "  7680  7680 65653  2175 33672  3050  7537  3821 65542 56450 26599 56130\n",
      " 57198 65653 33664 20830 33077  2175  5421     0 41323 24475 65542 32807\n",
      " 43930 64098 33672 58597 28077 29691 65909     0 45374 45808 22112 22169\n",
      " 32214     0 67417 65909  2084 21974  8256 33334 29691 23767 37530 37671\n",
      "  2175 32416 33334 29691 23767 29852 22167  7680  7680 65542 23547 18430\n",
      " 45176 22218  2626 58272 45090 33664 65638  2084   259 45808 45342 65542\n",
      " 31727 33664 20010  8854 60830 65542  9244 37993 66540 38416  2175 65542\n",
      " 62631 26984 60162  7680  7680 65542 17581 52359 41580 71831 46048 66339\n",
      " 39511     0 45374 45808 22210 21374 23593 68502 65542 43964 45808 29674\n",
      " 47587 29250  1809 29036 22390 16934 62614 27108   527  2175 70384 29950\n",
      " 62001 45808 11455  7680  7680  3362 30927 65772 33664 48398 30148 43108\n",
      " 12751 30148 36952  3812 63746 24475 21060 71997 65653  2175 33672 71424\n",
      "     0 62994 33334 65542 44151 45808 73608 21377]\n"
     ]
    }
   ],
   "source": [
    "print((features[122]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "def split(X, y, frac):\n",
    "    ln = len(y)\n",
    "    indexes = [r for r in range(0, ln)]\n",
    "    indexes = np.random.permutation(indexes)\n",
    "    test_frac = (1.0 - frac) / 2.0   \n",
    "    train_index = int(ln * frac)\n",
    "    test_index = train_index +  int(ln * test_frac)\n",
    "   \n",
    "    x_temp = np.array([X[i] for i in indexes])\n",
    "    y_temp = np.array([y[i] for i in indexes])\n",
    "    \n",
    "    x_train =  x_temp[: train_index]\n",
    "    x_test =  x_temp[train_index : test_index]\n",
    "    x_valid =  x_temp[test_index: ]\n",
    "    \n",
    "    y_train =  y_temp[: train_index]\n",
    "    y_test =  y_temp[train_index : test_index]\n",
    "    y_valid =  y_temp[test_index: ]\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, x_valid, y_valid\n",
    "\n",
    "x_train, y_train, x_test, y_test, x_valid, y_valid = split(features, targets, split_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 200)\n"
     ]
    }
   ],
   "source": [
    "print (x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lstm_size = 256\n",
    "lstm_layers = 1\n",
    "batch_size = 500\n",
    "n_embed = 300\n",
    "n_words = len(words_set)\n",
    "learning_rate = 0.1\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    with tf.name_scope('inputs'):\n",
    "        inputs_ = tf.placeholder(tf.int32, [None, None], name = 'inputs')\n",
    "        labels_ = tf.placeholder(tf.int32, [None, None], name = 'labels')\n",
    "        keep_prob = tf.placeholder(tf.float32, name = 'keep_prob')\n",
    "    \n",
    "    with tf.name_scope('embeddings'):\n",
    "        embeddings = tf.Variable(tf.truncated_normal([n_words, n_embed], stddev=0.1), name = 'embeddings')\n",
    "        embed = tf.nn.embedding_lookup(embeddings, inputs_, name = 'embed')\n",
    "        \n",
    "        \n",
    "    with tf.name_scope('lstm'):\n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)                                \n",
    "        cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "        initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "        \n",
    "    with tf.name_scope('forwqrd_path'):\n",
    "        outputs, final_state = tf.nn.dynamic_rnn(cell,  embed, initial_state = initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    predictions = tf.contrib.layers.fully_connected(outputs[:, -1], 1, activation_fn=tf.sigmoid)\n",
    "    cost = tf.losses.mean_squared_error(labels_, predictions)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels_)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size=100):\n",
    "    \n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10 Iteration: 5 Train loss: 0.510\n",
      "Epoch: 0/10 Iteration: 10 Train loss: 0.481\n",
      "Epoch: 0/10 Iteration: 15 Train loss: 0.435\n",
      "Epoch: 0/10 Iteration: 20 Train loss: 0.471\n",
      "Epoch: 0/10 Iteration: 25 Train loss: 0.509\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-c4fa319bb180>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mval_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m                     feed = {inputs_: x,\n\u001b[0;32m     29\u001b[0m                             \u001b[0mlabels_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_x' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    for e in range(epochs):\n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        for ii, (x, y) in enumerate(get_batches(x_train, y_train, batch_size), 1):\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y[:, None],\n",
    "                    keep_prob: 0.5,\n",
    "                    initial_state: state}\n",
    "            loss, state, _ = sess.run([cost, final_state, optimizer], feed_dict=feed)\n",
    "            \n",
    "            if iteration%5==0:\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Train loss: {:.3f}\".format(loss))\n",
    "\n",
    "            if iteration%25==0:\n",
    "                val_acc = []\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                for x, y in get_batches(x_valid, y_valid, batch_size):\n",
    "                    feed = {inputs_: x,\n",
    "                            labels_: y[:, None],\n",
    "                            keep_prob: 1,\n",
    "                            initial_state: val_state}\n",
    "                    batch_acc, val_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "                    val_acc.append(batch_acc)\n",
    "                print(\"Val acc: {:.3f}\".format(np.mean(val_acc)))\n",
    "            iteration +=1\n",
    "    saver.save(sess, \"checkpoints/sentiment.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_acc = []\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    for ii, (x, y) in enumerate(get_batches(test_x, test_y, batch_size), 1):\n",
    "        feed = {inputs_: x,\n",
    "                labels_: y[:, None],\n",
    "                keep_prob: 1,\n",
    "                initial_state: test_state}\n",
    "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.3f}\".format(np.mean(test_acc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 64",
   "language": "python",
   "name": "py35_64"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
